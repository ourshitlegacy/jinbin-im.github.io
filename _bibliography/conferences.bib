---
---

@string{aps = {American Physical Society,}}

@misc{
  author={Im,Jin-Bin and Rong-Lu and Hong,Jae-Ho J. and Zhang,Enlian and Shin,Seung-Hye and Joo,Moonboo and Lee,Ki-Won and Lee,Kang-Moo and Lee,Kyung-Ho and Park,Seo-Young and Kim,Ju-Hyung},
  year={2025},
  title={Effects of Visual Fidelity on Task Performance and Mental Workload in IVEs},
  journal={ISARC.Proceedings of the International Symposium on Automation and Robotics in Construction},
  volume={42},
  pages={909--916},
  address={Montreal, Canada},
  note={Copyright - Copyright IAARC Publications 2025; Last updated - 2025-09-03},
  abstract={Visual fidelity affects the user experience and performance in virtual environments. While past studies have explored its effects, most have relied on qualitative measures, and few quantitative studies have specified visual quality standards. This study examined the influence of visual fidelity on task performance and mental workload in immersive virtual environments (IVEs). Two environmental models were tested in virtual reality (VR) and mixed reality (MR): a high-visual quality model featuring detailed materials, realistic lighting, and outdoor scenery, and a low-fidelity research model with basic colors, dimensional lighting, and no external views. Sixty participants completed cognitive tasks (digit span, spatial working memory updating, go/no-go), while the EEG measured mental workload. The results showed that high-fidelity increased the cognitive load in complex tasks, whereas MR environments supported better performance. These findings emphasize the need to balance realism and cognitive demands to optimize virtual experiences.},
  keywords={Computers--Robotics; Workload; Visual tasks; Environment models; User experience; Virtual reality; Visual effects; Cognitive tasks; Quality standards; Mixed reality; Lighting; Task complexity; Virtual environments; Problem solving; Software; University students; Cognitive load; Automation; Realism; Workloads; Influence; Robotics; Decision making; Design; Variance analysis},
  language={English},
  url={https://www.proquest.com/conference-papers-proceedings/effects-visual-fidelity-on-task-performance/docview/3240509003/se-2},
}

@misc{
  author={Hong,Rong-Lu and Im,Jin-Bin and Park,Sang-Jun and Zhang,En-Lian and Ochirsuren,Nomgon and Beak,Young-Gun and Kang,Shin-Hyun and Chung,Seong-Won and Lee,Cheol-Su and Wang,Seunghyeon and Kim,Ju-Hyung},
  year={2025},
  title={Development of a Petrochemical Plant Pipe Counting Method Based on Improved Mask R-CNN and Transformer},
  journal={ISARC.Proceedings of the International Symposium on Automation and Robotics in Construction},
  volume={42},
  pages={972--979},
  address={Montreal, Canada},
  note={Copyright - Copyright IAARC Publications 2025; Last updated - 2025-09-03},
  abstract={In petrochemical plant construction, pipe installation critically the affects overall progress and costs, making accurate on-site pipe quantification essential. However, the wide range of pipe diameters, highdensity layouts, and complex site conditions poses significant challenges for automated counting methods. To address these issues, this study constructs the "PetroPipe" dataset, comprising 2,380 images (340 originals and 2,040 augmented) with pipes ranging from 0.75 to 60 inches in diameter under various resolutions. Multiple data augmentation strategies and a multi-stage training process enhance robustness under dynamic construction conditions. Building on this dataset, a pipe counting method is proposed that integrates instance segmentation with a counting head and a transformer encoder. Based on the Mask R-CNN framework, the model applies a discrete-bin classification approach to achieve accurate global quantity predictions, while maintaining high-quality instance-level detection and segmentation. The experimental results demonstrate that the developed model outperforms the standard Mask R-CNN model on the test set, increasing the counting accuracy from 65.55% without a counting head to 85.50%. When evaluated on an unlabelled 18-second video captured in a real-world scenario, it attained an accuracy of approximately 98.1%, demonstrating its capacity to adapt to practical industrial conditions. These results indicate that the proposed approach effectively accommodates varying pipe diameters, dense layouts, and complex backgrounds. Consequently, it provides a scalable, efficient pipe counting, progress monitoring, and resource optimization in petrochemical construction environments.},
  keywords={Computers--Robotics; Pipes; Layouts; Datasets; Data augmentation; Instance segmentation; Plant construction; Artificial neural networks; Chemical industry; Construction; Accuracy; Deep learning; Computer vision; Optimization; Radio frequency identification; Architecture; Automation; Human error; Onsite; Robotics},
  language={English},
  url={https://www.proquest.com/conference-papers-proceedings/development-petrochemical-plant-pipe-counting/docview/3240508942/se-2},
}

@misc{
  author={Jang,Jae-ho and Im,Jin-Bin and Zhang,En-Lian and Joo,Moon-Boo and Kang,Shin-Hyun and Kim,Ju-Hyung},
  year={2024},
  title={A Framework for Assessing the Learning Performance and Creativity in Spatial Features by Immersive Virtual Environments},
  journal={ICCEPM.Proceedings of the International Conference on Construction Engineering and Project Management},
  volume={42},
  pages={621--628},
  address={Sapporo, Japan},
  abstract={The development of immersive virtual environment (IVE) technologies has allowed for virtual simulations and exploration of architectural spaces before building the facilities. Although various researchers have implemented IVEs to demonstrate their effectiveness, these rigorous methods for evaluation have obtained little attention. For education facilities, learning environments are crucial factors influencing students' academic performance and attention. Previous studies have evaluated the capabilities of spaces in terms of the learning performance of students in actual conditions. However, various spatial features cannot be experienced in real-world situations despite the introduction of IVEs that can validate the learning performance. This study aims to propose a framework to compare learning abilities in real space and identical ones implemented by two different methods: Virtual Reality and Mixed Reality. To this end, various cognitive and creativity tests are conducted i.e., N-back, Go/No-go, Spatial working memory updating, and Torrance Test of Creative Thinking-verbal tests. Then,},
  language={English},
}
