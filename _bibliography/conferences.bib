---
---

@string{aps = {American Physical Society,}}

@inproceedings{ImISARC2025,
  author    = {Im, Jin-Bin and Hong, Rong-Lu and Hong, Jae-Ho and Zhang, Enlian and Shin, Seung-Hye and Joo, Moonboo and Lee, Ki-Won and Lee, Kang-Moo and Lee, Kyung-Ho and Park, Seo-Young and Kim, Ju-Hyung},
  year      = {2025},
  title     = {Effects of Visual Fidelity on Task Performance and Mental Workload in IVEs},
  booktitle = {Proceedings of the 42nd International Symposium on Automation and Robotics in Construction (ISARC)},
  pages     = {909--916},
  address   = {Montreal, Canada},
  note      = {Copyright IAARC Publications 2025; Last updated: 2025-09-03},
  abstract  = {Visual fidelity affects the user experience and performance in virtual environments. While past studies have explored its effects, most have relied on qualitative measures, and few quantitative studies have specified visual quality standards. This study examined the influence of visual fidelity on task performance and mental workload in immersive virtual environments (IVEs). Two environmental models were tested in virtual reality (VR) and mixed reality (MR): a high-visual quality model featuring detailed materials, realistic lighting, and outdoor scenery, and a low-fidelity research model with basic colors, dimensional lighting, and no external views. Sixty participants completed cognitive tasks (digit span, spatial working memory updating, go/no-go), while EEG measured mental workload. The results showed that high-fidelity increased cognitive load in complex tasks, whereas MR environments supported better performance. These findings emphasize the need to balance realism and cognitive demands to optimize virtual experiences.},
  keywords  = {Virtual reality, Mixed reality, Visual fidelity, Cognitive load, Task performance},
  language  = {English},
  url       = {https://www.proquest.com/conference-papers-proceedings/effects-visual-fidelity-on-task-performance/docview/3240509003/se-2}
}

@inproceedings{HongISARC2025,
  author    = {Hong, Rong-Lu and Im, Jin-Bin and Park, Sang-Jun and Zhang, En-Lian and Ochirsuren, Nomgon and Beak, Young-Gun and Kang, Shin-Hyun and Chung, Seong-Won and Lee, Cheol-Su and Wang, Seunghyeon
               and Kim, Ju-Hyung},
  year      = {2025},
  title     = {Development of a Petrochemical Plant Pipe Counting Method Based on Improved Mask R-CNN and Transformer},
  booktitle = {Proceedings of the 42nd International Symposium on Automation and Robotics in Construction (ISARC)},
  pages     = {972--979},
  address   = {Montreal, Canada},
  note      = {Copyright IAARC Publications 2025; Last updated: 2025-09-03},
  abstract  = {In petrochemical plant construction, pipe installation critically affects overall progress and costs, making accurate on-site pipe quantification essential. This study constructs the "PetroPipe" dataset, comprising 2,380 images under diverse resolutions and proposes a counting method integrating instance segmentation with a counting head and a transformer encoder. The model improves counting accuracy from 65.55\% to 85.50\% on the test set and achieves \~98.1\% on an unlabeled 18-second real-world video, demonstrating robustness in practical conditions.},
  keywords  = {Computer vision, Deep learning, Mask R-CNN, Transformer, Pipe counting, Construction automation},
  language  = {English},
  url       = {https://www.proquest.com/conference-papers-proceedings/development-petrochemical-plant-pipe-counting/docview/3240508942/se-2}
}

@inproceedings{JangICCEPM2024,
  author    = {Jang, Jae-ho and Im, Jin-Bin and Zhang, En-Lian and Joo, Moon-Boo and Kang, Shin-Hyun and Kim, Ju-Hyung},
  year      = {2024},
  title     = {A Framework for Assessing the Learning Performance and Creativity in Spatial Features by Immersive Virtual Environments},
  booktitle = {Proceedings of the International Conference on Construction Engineering and Project Management (ICCEPM)},
  volume    = {42},
  pages     = {621--628},
  address   = {Sapporo, Japan},
  url = {https://www.koreascience.kr/article/CFKO202431947392602.pdf},
  abstract  = {The development of immersive virtual environment (IVE) technologies has allowed for virtual simulations and exploration of architectural spaces before building facilities. This study proposes a framework to compare learning abilities in real space and identical ones implemented via VR and MR. Various cognitive and creativity tests are conducted (N-back, Go/No-go, spatial working memory updating, Torrance Test of Creative Thinking-verbal).},
  language  = {English}
}
